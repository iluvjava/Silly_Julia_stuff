{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Intro**\n",
    "\n",
    "We are interested in the convergence rate of the Conjugate Gradient Method and it's relationship to eigenvalues distributions. This notebook is a trying to replicate the experiment presented in Professor's Greenbaum's work in chapter 3 of the book. \n",
    "\n",
    "We consider a $n\\times n$ SPD matrix with eigenvalues paramaterized by: \n",
    "\n",
    "$$\n",
    "\\lambda_i = \\lambda_1 + \\frac{i - 1}{n - 1} \\rho^{n - i}, i = 2, \\cdots, n - 1\n",
    "$$\n",
    "\n",
    "Where $\\rho$ is taken to be a number between $0, 1$. The algorithm's behavior should be invariant under Unitary Transform. This is true due to the minmax polynomial property for the matrix polynomial. Therefore, the black box function will be using a diagonal matrix whose diagonal are values generated by the above expression. This makes the computational speed on exact arithematic faster. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### All the messy code is imported here. \n",
    "include(\"CG_Convergence.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Distribution of the Eigenvalues on the real line\n",
    "\n",
    "The expression generate a sequence of increasing eigenvalues. The sequence is oncreasing like the function $i\\rho^i$, uniform when $\\rho = 1$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 30\n",
    "λ1 = 0.001\n",
    "fig = plot(title=\"Eigenvalue Distribution\")\n",
    "Eigenvalues = nothing\n",
    "for ρ = [1, 0.9, 0.4]\n",
    "    EigenValues = Vector{Float64}()\n",
    "    for i in 1: n - 1 \n",
    "        push!(EigenValues, λ1 + ((i - 1)/(n - 1))*ρ^(n - i))\n",
    "    end\n",
    "    plot!(fig, EigenValues, label=\"ρ = $(ρ)\")\n",
    "    \n",
    "end\n",
    "display(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Floating Point Convergence Plot\n",
    "\n",
    "Let's try out for different values of $\\rho$ under Float64 Arithematic, using the Lanczos based Conjugate Gradient. \n",
    "\n",
    "**Important Information:** \n",
    "\n",
    "The algorithm in use under this context is the CG Based on the Lanczos Iteration and LDL decomposition of the Tridiagonal. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n = 50\n",
    "fig1 = plot(title=\"Resnorm2, n=$(n)\")\n",
    "fig2 = plot(title=\"Error Energy Norm\")\n",
    "\n",
    "for ρ = [0.1, 0.5, 0.8, 0.9, 1]\n",
    "    A = GetNastyPSDMatrix(ρ, n)  # A random matrix\n",
    "    b = rand(size(A, 2))\n",
    "    cg, Guesses, ResNorm = RunCGTillEnd(A, b, maxitr=2000, epsilon=1e-10)\n",
    "    plot!(fig1, ResNorm, label=\"ρ=$(ρ)\")\n",
    "    plot!(fig2, EnergyErrorNorm(A, b, Guesses), yaxis=:log10, label=\"ρ=$(ρ)\")\n",
    "    \n",
    "end\n",
    "plot(fig1, fig2, layout=(2, 1), size=(800, 800))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exact Arithematic Example**\n",
    "\n",
    "Now Let's try it out for Exact Arithemtic Computations. \n",
    "\n",
    "**Important Information**\n",
    "\n",
    "The algorithm in used here is the original version of the CG algorithm. Direct without the LDL decomposition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50\n",
    "fig1 = plot(title=\"Resnorm2, n=$(n)\")\n",
    "fig2 = plot(title=\"Error Energy Norm\")\n",
    "\n",
    "for ρ = [0.1, 0.5, 0.8, 0.9, 1]\n",
    "    A = GetNastyPSDMatrix(ρ, n)  # A random matrix\n",
    "    b = rand(size(A, 2))\n",
    "    A = convert(Matrix{Rational{BigInt}}, A)\n",
    "    b = convert(Vector{Rational{BigInt}}, b)\n",
    "    cg, Guesses, ResNorm = RunCGTillEnd(\n",
    "        A, b, \n",
    "        maxitr=2000, \n",
    "        epsilon=1e-10, \n",
    "        cg_implementation=Sproj.IterativeCGOriginal\n",
    "    )\n",
    "    plot!(fig1, ResNorm, label=\"ρ=$(ρ)\")\n",
    "    @info \"The Resnorm is: \\n $(ResNorm)\"\n",
    "    plot!(fig2, EnergyErrorNorm(A, b, Guesses) .|> log10.|> InfNan2Zero, label=\"ρ=$(ρ)\")\n",
    "    \n",
    "end\n",
    "plot(fig1, fig2, layout=(2, 1), size=(800, 800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
  },
  "kernelspec": {
   "display_name": "Julia 1.7.0",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
